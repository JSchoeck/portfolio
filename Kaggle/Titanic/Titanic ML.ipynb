{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic ML\n",
    "https://www.kaggle.com/c/titanic/\n",
    "\n",
    "#### Verwendetes Tutorial\n",
    "https://www.kaggle.com/jeffd23/scikit-learn-ml-from-start-to-finish\n",
    "\n",
    "#### Hiermit überarbeiten\n",
    "https://towardsdatascience.com/predicting-the-survival-of-titanic-passengers-30870ccc7e8\n",
    "- Importance\n",
    "- Features?\n",
    "\n",
    "###Eigene Arbeit\n",
    "- Vorhersage der wichtigsten ML Algorithmen vergleichen\n",
    "  - kNN\n",
    "  - HCR\n",
    "  - Decision Tree Classifier\n",
    "  - log Regressor?\n",
    "  - ...\n",
    "\n",
    "### Vorhersage\n",
    "- X_all: alle Features außer \"Survived\"\n",
    "- Y_all: nur \"Survived\"\n",
    "- Vergleichen mit simplen Modellen, zB alle Frauen / Kinder / mit Ticketpreis >x überleben\n",
    "\n",
    "### Datengewichtung\n",
    "- Gender +++\n",
    "- Pclass ++\n",
    "- SibSp ++\n",
    "- Embarked + -> in Tutorial als irrelevant bewertet\n",
    "\n",
    "### Datenbearbeitung\n",
    "- Age\n",
    "- Cabin\n",
    "- Fare\n",
    "- Name -> verworfen\n",
    "- Ticket? -> verworfen\n",
    "\n",
    "### Auffälligkeiten\n",
    "- Kabine G nur 4 Personen (je Mutter + Kind), wovon eine Paarung überlebt hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='log2', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=6, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8715083798882681\n",
      "Fold 1 accuracy: 0.7777777777777778\n",
      "Fold 2 accuracy: 0.8426966292134831\n",
      "Fold 3 accuracy: 0.7865168539325843\n",
      "Fold 4 accuracy: 0.8426966292134831\n",
      "Fold 5 accuracy: 0.8426966292134831\n",
      "Fold 6 accuracy: 0.8089887640449438\n",
      "Fold 7 accuracy: 0.797752808988764\n",
      "Fold 8 accuracy: 0.8089887640449438\n",
      "Fold 9 accuracy: 0.8539325842696629\n",
      "Fold 10 accuracy: 0.8539325842696629\n",
      "Mean Accuracy: 0.8215980024968788\n",
      "Standard Deviation: 0.027320293969793068\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from numpy import median\n",
    "\n",
    "#########\n",
    "# Datenimport & Merging\n",
    "data_train = pd.read_csv('./Titanic/train.csv')\n",
    "data_test = pd.read_csv('./Titanic/test.csv')\n",
    "\n",
    "#########\n",
    "# Data Wrangling methods\n",
    "def simplify_ages(df):\n",
    "    df.Age = df.Age.fillna(-0.5)\n",
    "    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n",
    "    group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "    categories = pd.cut(df.Age, bins, labels=group_names)\n",
    "    df.Age = categories\n",
    "    return df\n",
    "def simplify_cabins(df):\n",
    "    df.Cabin = df.Cabin.fillna('N')\n",
    "    df.Cabin = df.Cabin.apply(lambda x: x[0]) # Nur erstes Zeichen behalten; apply führt Funktion in ganzer Achse/Spalte aus\n",
    "    return df\n",
    "def simplify_embarked(df):\n",
    "    df.Embarked = df.Embarked.fillna('N')\n",
    "    return df\n",
    "def simplify_fare(df):\n",
    "    df.Fare = df.Fare.fillna(-0.5)\n",
    "    bins = (-1, 0, 8, 15, 31, 513)\n",
    "#     bins = (-1, 0, 8, 15, 31, 1000) # keine Veränderung, da Fare.max = 512.4\n",
    "    group_names = [\"Unknown\", \"quart1\", \"quart2\", \"quart3\", \"quart4\"]\n",
    "    categories = pd.cut(df.Fare, bins, labels=group_names)\n",
    "    df.Fare = categories\n",
    "    return df\n",
    "def format_name(df):\n",
    "    df['LName'] = df.Name.apply(lambda x: x.split(' ')[0])\n",
    "    df['NamePrefix'] = df.Name.apply(lambda x: x.split(' ')[1])\n",
    "    return df\n",
    "def drop_features(df):\n",
    "    return df.drop(['Ticket', 'Name', 'Embarked'], axis=1)\n",
    "#     return df.drop(['Ticket', 'Name'], axis=1) # Bedeutung von Embarked prüfen\n",
    "def transform_feature(df):\n",
    "    df = simplify_ages(df)\n",
    "    df = simplify_cabins(df)\n",
    "    df = simplify_fare(df)\n",
    "    df = simplify_embarked(df)\n",
    "    df = format_name(df)\n",
    "    df = drop_features(df)\n",
    "    return df\n",
    "from sklearn import preprocessing\n",
    "def encode_features(df_train, df_test):\n",
    "    '''Wandelt Features in Zahlen um, die sonst nur in Strings vorliegen. Ermöglichst Verwendung div. Algorithmen.'''\n",
    "    features = ['Fare', 'Cabin', 'Age', 'Sex', 'LName', 'NamePrefix']\n",
    "#     features = ['Fare', 'Cabin', 'Embarked', 'Age', 'Sex', 'LName', 'NamePrefix'] # Bedeutung von Embarked prüfen\n",
    "    df_combined = pd.concat([df_train[features], df_test[features]])\n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder() # OneHotEncoder bessere Wahl bei kategorischen und nicht skalaren Größen?\n",
    "        le = le.fit(df_combined[feature])\n",
    "        df_train[feature] = le.transform(df_train[feature])\n",
    "        df_test[feature] = le.transform(df_test[feature])\n",
    "    return df_train, df_test\n",
    "\n",
    "#########\n",
    "# Data Exploration & Data Wrangling execution\n",
    "\n",
    "data_train = transform_feature(data_train)\n",
    "data_test = transform_feature(data_test)\n",
    "\n",
    "# sns.barplot(x=\"Embarked\", y=\"Survived\", hue=\"Sex\", data=data_train)\n",
    "# sns.barplot(x=\"SibSp\", y=\"Survived\", hue=\"Sex\", data=data_train)\n",
    "# sns.barplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=data_train)\n",
    "# sns.barplot(x=\"Age\", y=\"Survived\", hue=\"Sex\", data=data_train)\n",
    "# sns.barplot(x=\"Fare\", y=\"Survived\", hue=\"Sex\", data=data_train)\n",
    "# sns.barplot(x=\"Cabin\", y=\"Survived\", hue=\"Sex\", data=data_train)\n",
    "# sns.barplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=data_train)\n",
    "\n",
    "data_train, data_test = encode_features(data_train, data_test)\n",
    "\n",
    "#########\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_all = data_train.drop(['Survived', 'PassengerId'], axis=1) # axis=1 notwendig, da default =0 -> Zeile statt Spalte gesucht\n",
    "X_test_all = data_test\n",
    "Y_all = data_train['Survived']\n",
    "num_test = 0.20 # 80% zum Trainieren nutzen, Testen gegen 20 %\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_all, Y_all, test_size=num_test, random_state=69) # 23 im Tutorial\n",
    "\n",
    "## Algorithmus\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "# clf = # Alternative classifier testen\n",
    "\n",
    "parameters = {'n_estimators': [4, 6, 9], 'max_features': ['log2', 'sqrt', 'auto'],\n",
    "             'criterion': ['entropy', 'gini'], 'max_depth': [2, 3, 5, 10],\n",
    "             'min_samples_split': [2, 3, 5], 'min_samples_leaf': [1, 5, 8]\n",
    "             } # Parameter variieren\n",
    "\n",
    "# Typ des scoring Mechanismus\n",
    "acc_scorer = make_scorer(accuracy_score) \n",
    "# Grid Search\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=acc_scorer, cv=5) # cv in zukünftigen Releases default 5 statt 3\n",
    "grid_obj = grid_obj.fit(X_train, Y_train) # mit Features in X Vorhersage des Features Y trainieren\n",
    "clf = grid_obj.best_estimator_ # Beste Parameterkombination verwenden\n",
    "clf.fit(X_train, Y_train) # Besten Algorithmus auf Daten anwenden\n",
    "predictions = clf.predict(X_test)\n",
    "print(accuracy_score(Y_test, predictions))\n",
    "\n",
    "#########\n",
    "# Algorithmen vergleichen mit KFold\n",
    "from sklearn.model_selection import KFold # Tutorial hat veraltetes Untermodul cross_validation\n",
    "\n",
    "def run_kfold(clf):\n",
    "#    kf = KFold(891, n_folds=10) # 891 wegen Datensatzlänge? - veraltete Parameter!\n",
    "    kf = KFold(n_splits=10)\n",
    "    outcomes = []\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf.split(X_all):\n",
    "        fold += 1\n",
    "        X_train, X_test = X_all.values[train_index], X_all.values[test_index]\n",
    "        Y_train, Y_test = Y_all.values[train_index], Y_all.values[test_index]\n",
    "        clf.fit(X_train, Y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(Y_test, predictions)\n",
    "        outcomes.append(accuracy)\n",
    "        print('Fold {0} accuracy: {1}'.format(fold, accuracy))\n",
    "    mean_outcome = np.mean(outcomes)\n",
    "    std_outcome = np.std(outcomes)\n",
    "    print('Mean Accuracy: {0}'.format(mean_outcome))\n",
    "    print('Standard Deviation: {0}'.format(std_outcome))\n",
    "    return\n",
    "\n",
    "run_kfold(clf)\n",
    "        \n",
    "#########\n",
    "# Testoutput\n",
    "# data_train.sample(3)\n",
    "# data_test.sample(3)\n",
    "# data_train.Fare.describe()\n",
    "# X_train.sample(3)\n",
    "# data_train[(data_train.Embarked != 'S') & (data_train.Embarked != 'Q') & (data_train.Embarked != 'C')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del sub_df,Sub_PassengerIds,submission,X_test_submit\n",
    "#print(predictions)\n",
    "#X_test\n",
    "X_test_submit = X_test_all.drop('PassengerId', axis=1)\n",
    "Sub_PassengerIds = X_test_all[['PassengerId']]\n",
    "submission = clf.predict(X_test_submit)\n",
    "\n",
    "sub_df = pd.DataFrame(data=Sub_PassengerIds, columns=['PassengerId'])\n",
    "sub_df['Survived'] = submission\n",
    "sub_df.to_csv('./Titanic/submit_RFC_20200428C.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ergebnisse\n",
    "- Standard: 10 Splits mit KFold\n",
    "\n",
    "## Mit Embarked\n",
    "### LabelEncoder und RFC\n",
    "- 0.822\n",
    "- 0.819\n",
    "- 100 Splits: 0.820\n",
    "\n",
    "### OneHotEncoder und RFC\n",
    "- ...\n",
    "\n",
    "## Ohne Embarked\n",
    "### LabelEncoder und RFC\n",
    "- 0.829\n",
    "- 0.818\n",
    "- 100 Splits: 0.825\n",
    "- Stddev 3.6%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
